{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"customLayersModels.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMD29LkOkYRtoypHGtY2RUM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":36,"metadata":{"id":"eEw09CccuOSw","executionInfo":{"status":"ok","timestamp":1641550309716,"user_tz":-540,"elapsed":280,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","source":["# 0. The most basic building block"],"metadata":{"id":"MqtwNexculsk"}},{"cell_type":"markdown","source":["## 0.1 Trainable layer"],"metadata":{"id":"0n_FkS41wCX8"}},{"cell_type":"code","source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units = 32, input_dim = 32):\n","        # units: dimension of an output\n","        super().__init__()\n","        # initalize weights\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(\n","            initial_value = w_init(shape = (input_dim, units), dtype = 'float32'),\n","            trainable = True,\n","            name = 'w'\n","        )\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(\n","            initial_value = b_init(shape= (units, ), dtype= 'float32'),\n","            trainable = True,\n","            name = 'b'\n","        )\n","\n","    def call(self, x):\n","        return tf.matmul(x,self.w) + self.b"],"metadata":{"id":"jZhjzY4ouUw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["linear = Linear(4,2)\n","x = tf.ones((2,2))\n","linear(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDYLr3CqvhbO","executionInfo":{"status":"ok","timestamp":1641545621743,"user_tz":-540,"elapsed":504,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"6eaa0c02-9dac-4af0-e134-295ab8958990"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n","array([[-0.03611   ,  0.01389586,  0.04623048, -0.09226894],\n","       [-0.03611   ,  0.01389586,  0.04623048, -0.09226894]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Note that the weights w and b are automatically tracked by the layer upon being set as a layer attributes.\n","linear.weights == [linear.w, linear.b]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8b9jwUpvlsd","executionInfo":{"status":"ok","timestamp":1641545692043,"user_tz":-540,"elapsed":261,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"c4a26878-0b58-49dc-e939-e66e1460c196"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## 0.2 Non trainable layer"],"metadata":{"id":"G0WduWdIwHMQ"}},{"cell_type":"code","source":["# Layers can have non-trainable weights.\n","# Besides trainable weights, you can add non-trainable weights to a layer as well.\n","# Such weights are meant not to be taken into account during backpropagation\n","# when you are training the layer.\n","class ComputeSum(keras.layers.Layer):\n","    def __init__(self, input_dim):\n","        super(ComputeSum, self).__init__()\n","        self.total = tf.Variable(initial_value= tf.zeros((input_dim, )), trainable= False)\n","\n","    def call(self, x):\n","        # return column sum.\n","        # sum by row (0)\n","        # assign and add the element which have been summed along the row axis to the self.total\n","        # the summation is accumulated as it recevies \"call\"s.\n","        return self.total.assign_add(tf.reduce_sum(x, axis= 1))"],"metadata":{"id":"GEmZ6dkEvvss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = tf.ones((2,3)) # [[1,1,1],[1,1,1]]\n","my_sum = ComputeSum(x.shape[0])\n","y = my_sum(x)\n","print(y.numpy()) # [3,3]\n","y = my_sum(x)\n","print(y.numpy()) # [6,6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuQg6fO7xqOu","executionInfo":{"status":"ok","timestamp":1641546694145,"user_tz":-540,"elapsed":274,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"162203f4-407b-4edb-83f2-55b5b6c2b565"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3. 3.]\n","[6. 6.]\n"]}]},{"cell_type":"code","source":["# it's part of layer.weights, but it gets categorized as a non-trainable weight:\n","print(\"weights: \", len(my_sum.trainable_weights))\n","print(\"non-trainable weights: \", len(my_sum.non_trainable_weights))\n","\n","print(\"trainable weights: \", my_sum.trainable_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PchRiODxs9V","executionInfo":{"status":"ok","timestamp":1641546722825,"user_tz":-540,"elapsed":248,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"f446b2bf-d2e3-4efb-a73e-0dbd70fc0646"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weights:  0\n","non-trainable weights:  1\n","trainable weights:  []\n"]}]},{"cell_type":"markdown","source":["## 0.3 Deferring weight creation util the shape of the inputs is known"],"metadata":{"id":"8LkFTWdVz43F"}},{"cell_type":"code","source":["# Our Linear layer above took an input_dimargument that was used to compute the shape of the weight\n","# w and b in __init__()\n","\n","# Use build method to create a layer.\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units= 32):\n","        # input_dim is determined after the shape of the inputs is known.\n","        super(Linear, self).__init__()\n","        self.units= units\n","\n","    def build(self, input_shape):\n","        # We do not know the input_shape yet.\n","        # Use self.add_weight\n","        self.w = self.add_weight(\n","            shape= (input_shape[-1], self.units),\n","            initializer = \"random_normal\",\n","            trainable = True\n","        )\n","        self.b = self.add_weight(\n","            shape = (self.units, ),\n","            initializer = \"random_normal\",\n","            trainable = True\n","        )\n","    \n","    def call(self, x):\n","        return tf.matmul(x, self.w) + self.b\n"],"metadata":{"id":"yd-pIVRVz-Dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# At instantiation, we don't know on what inputs this is going to get called.\n","linear_layer = Linear(32)\n","\n","# The layer's weights are created dynamically the first time the layer is called.\n","y = linear_layer(x)"],"metadata":{"id":"CarI5jj90nBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"vp34cSAo06ze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Various Layer Block    \n"],"metadata":{"id":"QLQkQMYP09J9"}},{"cell_type":"markdown","source":["## 1.1 Multi layer perceptron block     \n","Layers are recursively composable."],"metadata":{"id":"uUcmAA8F2_1u"}},{"cell_type":"code","source":["class MLPBlock(keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear1 = Linear(32)\n","        self.linear2 = Linear(16)\n","        self.linear3 = Linear(8)\n","\n","    def call(self, x):\n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        x = self.linear3(x)\n","        return x"],"metadata":{"id":"nJZxShCk1FQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlp = MLPBlock()\n","y = mlp(tf.ones(shape=(3,64))) # The first call to the mlp will create the weights\n","print(\"weights:\", len(mlp.weights))\n","print(\"trainable weights:\", len(mlp.trainable_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHN2NYKa1d5O","executionInfo":{"status":"ok","timestamp":1641547235524,"user_tz":-540,"elapsed":2,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"5c4a93df-0ccd-4878-edbd-09576f114ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weights: 6\n","trainable weights: 6\n"]}]},{"cell_type":"code","source":["mlp.weights"],"metadata":{"id":"uQKdnJw_1r9P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 The add_loss() method    \n","When writing the call() method of a layer, you can create loss tensors that you will want to use later      \n","When writing your training loop.      \n","This is doable by calling self.add_loss(value)"],"metadata":{"id":"_soq4RUM2HnF"}},{"cell_type":"code","source":["# A layer that creates an activity regularization loss.\n","class ActivityRegularizationLayer(keras.layers.Layer):\n","    def __init__(self, rate= 1e-2):\n","        super(ActivityRegularizationLayer, self).__init__()\n","        self.rate = rate\n","    \n","    def call(self, inputs):\n","        self.add_loss(self.rate * tf.reduce_sum(inputs))\n","        return inputs\n","    # These losses can be retrieved via layer.losses. This property is reset at the start of\n","    # every __call__() to the top-level layer, so that layer.losses\n","    # always contains the loss values created during the last forward pass.  \n","\n","class OuterLayer(keras.layers.Layer):\n","    def __init__(self):\n","        super(OuterLayer, self).__init__()\n","        self.activity_reg = ActivityRegularizationLayer(1e-2)\n","\n","    def call(self, inputs):\n","        return self.activity_reg(inputs)"],"metadata":{"id":"L7CqPidG2MxE","executionInfo":{"status":"ok","timestamp":1641550447916,"user_tz":-540,"elapsed":269,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["layer = OuterLayer()\n","assert len(layer.losses) == 0\n","_ = layer(tf.zeros(1,1))\n","assert len(layer.losses) == 1\n","\n","# layer.losses gets rest at the start of each __call__\n","_ = layer(tf.ones((1,1)))\n","assert len(layer.losses) == 1\n","\n","print(layer.losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NShAT_PsBglb","executionInfo":{"status":"ok","timestamp":1641550528538,"user_tz":-540,"elapsed":272,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"9e415534-1ffa-4e61-d994-1628259e6d94"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.01>]\n"]}]},{"cell_type":"markdown","source":["## 1.3 Kernel regularizer      \n","[Regularizers](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/Regularizer)     \n","* `kernel_regularizer`: Regularizer to apply a penalty on the layer's kernel\n","* `bias_regularizer`: Regularizer to apply a penalty on the layer's bias\n","* `activity_regularizer`: Regularizer to apply a penalty on the layer's output"],"metadata":{"id":"MkycBBMwCljc"}},{"cell_type":"markdown","source":["```python\n","# Available penalties\n","tf.keras.regularizers.L1(0.3)  # L1 Regularization Penalty\n","tf.keras.regularizers.L2(0.1)  # L2 Regularization Penalty\n","tf.keras.regularizers.L1L2(l1=0.01, l2=0.01)  # L1 + L2 penalties\n","\n","```"],"metadata":{"id":"vKuIOsBkEeqP"}},{"cell_type":"code","source":["class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n","    def __init__(self, kernel_reg_rate = 1e-3):\n","        super(OuterLayerWithKernelRegularizer, self).__init__()\n","        self.dense = keras.layers.Dense(\n","            32,\n","            activation= 'relu',\n","            use_bias = True,\n","            activity_regularizer= None,\n","            kernel_regularizer = tf.keras.regularizers.l2(1e-3)\n","        )\n","    \n","    def call(self, inputs):\n","        return self.dense(inputs)\n","         "],"metadata":{"id":"ohTsw860Bzj0","executionInfo":{"status":"ok","timestamp":1641551610276,"user_tz":-540,"elapsed":283,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["## 1.3 Regularizers in details   "],"metadata":{"id":"cmvS8JIoDvLD"}},{"cell_type":"markdown","source":["### 1.3.1 Directly calling a regularizer"],"metadata":{"id":"Xnkkh1S7EA2O"}},{"cell_type":"code","source":["regularizer = tf.keras.regularizers.L2(2.)\n","kernel = tf.ones(shape=(5, 5))\n","regularizer(kernel) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZMXRTNNCE23","executionInfo":{"status":"ok","timestamp":1641551161895,"user_tz":-540,"elapsed":301,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"54773839-b837-4d0c-f0c9-1320b71b6852"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=50.0>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["### 1.3.2 Developing new regularizers\n","\n","Any function that takes in a weight matrix and returns a scalar tensor can be used as a regularizer.\n"],"metadata":{"id":"NLABeg-SEvp6"}},{"cell_type":"code","source":["@tf.keras.utils.register_keras_serializable(package='Custom', name='myl1')\n","def l1_reg(weight_matrix):\n","    return 0.01 * tf.math.reduce_sum(tf.math.abs(weight_matrix))\n","\n","class L1CustomLossLayer(keras.layers.Layer):\n","    def __init__(self):\n","        super(L1CustomLossLayer, self).__init__()\n","        self.dense = keras.layers.Dense(\n","            32,\n","            activation= 'relu',\n","            use_bias = True,\n","            activity_regularizer= l1_reg,\n","            kernel_regularizer = None\n","        )\n","\n","    def call(self, inputs):\n","        return self.dense(inputs)"],"metadata":{"id":"h-xjOlCJFfAo","executionInfo":{"status":"ok","timestamp":1641552000544,"user_tz":-540,"elapsed":248,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["layer = L1CustomLossLayer()\n","inputs = tf.ones(shape= (3,4))\n","layer(inputs)\n","print(layer.losses) # 0.01 * tf.reduce_sum(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie2Oxe1mF-8Q","executionInfo":{"status":"ok","timestamp":1641552002230,"user_tz":-540,"elapsed":4,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"662e2395-2f1c-4131-a8b5-a59af657521b"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.08917602>]\n"]}]},{"cell_type":"code","source":["# Registration is required for Keras model_to_estimator, \n","# saving and loading models to HDF5 formats, Keras model cloning, \n","# some visualization utilities, and exporting models to and from JSON\n","@tf.keras.utils.register_keras_serializable(package='Custom', name='myl2') \n","class L2Regularizer(tf.keras.regularizers.Regularizer):\n","    def __init__(self, l2= 0.):\n","        self.l2 = l2\n","    \n","    def __call__(self, x):\n","        return self.l2 * tf.math.reduce_sum(tf.math.square(x))\n","    \n","    def get_config(self):\n","        return {'l2':float(self.l2)}"],"metadata":{"id":"UYdIWJhqET1-","executionInfo":{"status":"ok","timestamp":1641553386995,"user_tz":-540,"elapsed":275,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["@tf.keras.utils.register_keras_serializable(package='Custom', name='myl1l2')\n","class L1L2Regularizer(tf.keras.regularizers.Regularizer):\n","    def __init__(self, l1= 0., l2= 0.):\n","        self.l1, self.l2 = l1, l2\n","    \n","    def __call__(self, inputs):\n","        return self.l1 * tf.math.reduce_sum(tf.math.abs(inputs)) + self.l2 * tf.math.reduce_sum(tf.math.square(inputs))\n","    \n","    def get_config(self):\n","        return {'l1':float(self.l1), 'l2':float(self.l2)}"],"metadata":{"id":"Le7EvJXLIzxL","executionInfo":{"status":"ok","timestamp":1641553393622,"user_tz":-540,"elapsed":247,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["class L2CustomLossLayer(keras.layers.Layer):\n","    def __init__(self, l1 = 1e-2, l2 = 1e-2):\n","        super(L2CustomLossLayer, self).__init__()\n","        self.l1, self.l2 = l1, l2\n","        self.dense = keras.layers.Dense(\n","            units = 32,\n","            activation = 'relu',\n","            kernel_regularizer= L2Regularizer(l2= self.l2)\n","        )\n","    \n","    def call(self, x):\n","        return self.dense(x)\n","    "],"metadata":{"id":"SmLcchgLIFlf","executionInfo":{"status":"ok","timestamp":1641553398329,"user_tz":-540,"elapsed":251,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["layer = L2CustomLossLayer()\n","inputs = tf.ones((3,4), dtype= tf.float32)\n","layer(inputs)\n","print(layer.losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAhhwk8YIsQG","executionInfo":{"status":"ok","timestamp":1641553398622,"user_tz":-540,"elapsed":9,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"b0441a37-3afa-4f15-c043-1fa079cef3a0"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.067631654>]\n"]}]},{"cell_type":"markdown","source":["A note on serialization and deserialization:    \n","(@tf.keras.utils.register_keras_serializable(package='Custom', name='myl2'))    \n","\n","    \n","(1) Registering the regularizers as serializable is optional if you are just training and executing models, exporting to and from SavedModels, or saving and loading weight checkpoints.\n","    \n","(2) Registration is required for Keras model_to_estimator, saving and loading models to HDF5 formats, Keras model cloning, some visualization utilities, and exporting models to and from JSON. If using this functionality, you must make sure any python process running your model has also defined and registered your custom regularizer."],"metadata":{"id":"kdUvvfEZFfcd"}},{"cell_type":"markdown","source":["### 1.3.3 Losses during the training step"],"metadata":{"id":"BD69j_lONWaL"}},{"cell_type":"markdown","source":["```python\n","# Those losses are meant to be taken into account when writing training loops like this:\n","# instantiate an optimizer...\n","optimizer = tf.keras.optimizer.SGD(learning_rate= 1e-3)\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits= True) \n","\n","# Iterate over the batches of a dataset.\n","for x_batch_train, y_batch_train in train_dataset:\n","    with tf.GradientTape() ad tape:\n","        logits = layer(x_batch_train)\n","        loss_value = loss_fn(y_batch_train, logits)\n","        # Add extra losses created during this forward loss.\n","        loos_value += sum(model.losses)\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","```"],"metadata":{"id":"eV862fSLNnfj"}},{"cell_type":"code","source":["# These losses also work seamlessly with fit() \n","# they get automatically summed and added to the main loss, if any.\n","\n","import numpy as np\n","\n","inputs = keras.Input(shape= (3,))\n","outputs = ActivityRegularizationLayer()(inputs)\n","model = keras.Model(inputs, outputs)\n","\n","# If there is a loss passed in compile, the regularization\n","# losses get added to it.\n","model.compile(optimizer= 'adam', loss = 'mse')\n","model.fit(np.random.random((2,3)), np.random.random((2,3)))\n","\n","# It's also possible not to pass any loss in compile\n","# since the model already ahs a loss to minimze, via the add_loss\n","# call during the forward pass!\n","model.compile(optimizer = 'adam')\n","model.fit(np.random.random((2,3)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocdOiIquNcG4","executionInfo":{"status":"ok","timestamp":1641553838005,"user_tz":-540,"elapsed":683,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"0c3be57f-239d-423c-859e-fcf1c7ba6776"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 166ms/step - loss: 0.1315\n","1/1 [==============================] - 0s 67ms/step - loss: 0.0351\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f14036fa650>"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","source":["## 1.4 The add_metric() method  \n","Similarly to add_loss(), layers also have an add_metric() method for tracking the moving average of a quantity during training.    \n","Consider the following layer."],"metadata":{"id":"OqY0dkPxPfcz"}},{"cell_type":"code","source":["class LogisticEndpoint(keras.layers.Layer):\n","    def __init__(self, name= None):\n","        super(LogisticEndpoint, self).__init__(name= name)\n","        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits= True)\n","        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n","        \n","    def call(self, targets, logits, sample_weights=None):\n","        # Compute the training-time loss value and add it to the\n","        # layer using self.add_loss()\n","        loss = self.loss_fn(targets, logits, sample_weights)\n","        self.add_loss(loss)\n","\n","        # Log accuarcy as a metric and add it\n","        # to the layer using self.add_metric()\n","        acc = self.accuracy_fn(targets, logits, sample_weights)\n","        self.add_metric(acc, name= 'accuracy')\n","\n","        # Return the inference-time prediction tensor. (for .predict())\n","        return tf.nn.softmax(logits)"],"metadata":{"id":"Ty3MGrdWP9ht","executionInfo":{"status":"ok","timestamp":1641554685150,"user_tz":-540,"elapsed":290,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["# Metrics tracked in this way are accessible via layer.metrics:\n","layer = LogisticEndpoint()\n","targets = tf.ones((2,2))\n","logits = tf.ones((2,2))\n","y = layer(targets, logits)\n","\n","print(\"layer.metrics: \", layer.metrics)\n","print(\"current accuracy value:\", float(layer.metrics[0].result()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMaXlpzWSEHz","executionInfo":{"status":"ok","timestamp":1641554685441,"user_tz":-540,"elapsed":4,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"bed55eae-b196-4cf7-c7b7-25e33d5fe23e"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["layer.metrics:  [<keras.metrics.BinaryAccuracy object at 0x7f1404f37c10>]\n","current accuracy value: 1.0\n"]}]},{"cell_type":"code","source":["# Just like for add_loss(), these metrics are tracked by fit()\n","inputs = keras.Input(shape=(3,), name= \"inputs\")\n","targets = keras.Input(shape=(10,), name= \"targets\")\n","logits = keras.layers.Dense(10)(inputs)\n","predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n","\n","model = keras.Model(inputs = [inputs, targets], outputs= predictions)\n","model.compile(optimizer= 'adam')\n","\n","data = {\n","    \"inputs\":np.random.random((3,3)),\n","    \"targets\":np.random.random((3,10))\n","}\n","\n","model.fit(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"moxdb79cSO3i","executionInfo":{"status":"ok","timestamp":1641554771957,"user_tz":-540,"elapsed":729,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"a1c55e8d-5ba5-4637-b3a4-9aec3ecaaeb9"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 360ms/step - loss: 1.0126 - binary_accuracy: 0.0000e+00\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f140d9cbb50>"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["model.metrics_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lII4BRK7SX8a","executionInfo":{"status":"ok","timestamp":1641554772620,"user_tz":-540,"elapsed":4,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"77d5a3fd-abc5-4ef6-a01b-b309db2cb248"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['loss', 'binary_accuracy']"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","source":["## 1.5 Optionally enabling serialization on your layers"],"metadata":{"id":"QvDnKO8_Rver"}},{"cell_type":"code","source":["class Linear(keras.layers.Layer):\n","    def __init__(self, units= 32):\n","        super(Linear, self).__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape = (input_shape, self.units),\n","            initializer = \"random_normal\",\n","            trainable = True\n","        )\n","        self.b = self.add_weight(\n","            shape = (self.units, ),\n","            initializer = \"random_normal\",\n","            trainable = True\n","        )\n","    \n","    def call(self, x):\n","        return tf.matmul(x, self.w) + self.b\n","    \n","    def get_config(self):\n","        return {\"units\": self.units}"],"metadata":{"id":"rnSGTQQ2Srha","executionInfo":{"status":"ok","timestamp":1641555127761,"user_tz":-540,"elapsed":254,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# Now you can recreate the layer from its config:\n","layer = Linear(64)\n","config = layer.get_config()\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxdwujC8T1fg","executionInfo":{"status":"ok","timestamp":1641555157605,"user_tz":-540,"elapsed":9,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"5f52d251-c43a-426b-dac1-c1f0204d05bd"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["{'units': 64}\n"]}]},{"cell_type":"code","source":["# recreate\n","new_layer = Linear.from_config(config)"],"metadata":{"id":"iQTvEw7CT9-7","executionInfo":{"status":"ok","timestamp":1641555173556,"user_tz":-540,"elapsed":254,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":["# 2. Some useful options"],"metadata":{"id":"ZolYYiP6U9IB"}},{"cell_type":"markdown","source":["##. 2.1 Arguments of \\_\\_init__() method"],"metadata":{"id":"cSr1QN9yVF3P"}},{"cell_type":"code","source":["# Note that the __init__() method of the base Layer class takes some keyword arguments,\n","# In particular a name and a dtype.\n","# It's good practice to pass these arguments to the parent class in \n","# __init__() and to include them in the layer config.\n","class Linear(keras.layers.Layer):\n","\n","    def __init__(self, units= 32, **kargs):\n","        super(Linear, self).__init__(**kargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape = (input_shape[-1], self.units),\n","            initializer = \"random_normal\",\n","            trainable = True\n","        )\n","        self.b = self.add_weight(\n","            shape = (self.units,), \n","            initializer = \"random_normal\",\n","            trainable = True\n","        )        \n","\n","    def call(self, x):\n","        return tf.matmul(x, self.w) + self.b\n","\n","###################################################\n","    def get_config(self):                         #\n","        config = super(Linear, self).get_config() #\n","        config.update({\"units\": self.units})      #\n","        return config                             #\n","###################################################\n","\n","layer = Linear(64)\n","config = layer.get_config()\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR2qrMeAVLZj","executionInfo":{"status":"ok","timestamp":1641555691911,"user_tz":-540,"elapsed":266,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"a9368e5f-5066-41b7-f57b-0d452278bdaf"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["{'name': 'linear_10', 'trainable': True, 'dtype': 'float32', 'units': 64}\n"]}]},{"cell_type":"markdown","source":["### 2.2 Privileged training argument in the call() method\n","* training: boolean"],"metadata":{"id":"N1RFHSbtWCty"}},{"cell_type":"code","source":["class CustomDropout(keras.layers.Layer):\n","    def __init__(self, rate, **kargs):\n","        super(CustomDropout, self).__init__(**kargs)\n","        self.rate = rate\n","    \n","    def call(self, x, training = None):\n","        if training:\n","            return tf.nn.dropout(x, rate= self.rate)\n","        return x\n","\n","# mask argument\n","# You will find it in all keras RNN layers\n","# A mask is a boolean tensor (one boolean value per timestep in the input)\n","# used to skip certain input timesteps when processing tim-series data\n","# Keras will automatically  pass the correct mask argument to __call__() for layers\n","# that support it. when a mask is generated by a prior layer."],"metadata":{"id":"7oZooKoDV74F","executionInfo":{"status":"ok","timestamp":1641555914770,"user_tz":-540,"elapsed":257,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["# When to use layer or model\n","# fit(), save() --> model\n","# basic building block --> layer"],"metadata":{"id":"s5VWMy-jW2vp","executionInfo":{"status":"ok","timestamp":1641555926164,"user_tz":-540,"elapsed":282,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":["# 3. When to use layer or model     \n","\n","\n","*   fit(), save() --> model\n","*   basic building block --> layer\n","\n"],"metadata":{"id":"iGvmi7_aW-5b"}},{"cell_type":"markdown","source":["\n","\n","```python\n","# Example: ResNet\n","class ResNet(tf.keras.Model):\n","    \n","    def __init__(self):\n","        super(ResNet, self).__init__()\n","        self.block_1 = ResNetBlock()\n","        self.block_2 = ResNetBlock()\n","        self.global_pool = layers.GlobalAveragePooling2D()\n","        self.classifier = keras.layers.Dense(num_classes)\n","\n","    def call(self, x):\n","        x = self.block_1(x)\n","        x = self.block_2(x)\n","        x = self.global_pool(x)\n","        x = self.classifier(x)\n","        return x\n","```\n","\n"],"metadata":{"id":"5--ylnaVW82A"}},{"cell_type":"code","source":[""],"metadata":{"id":"Yt9EVNDDW5n4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Putting it all together..."],"metadata":{"id":"OLOoULUoXSpB"}},{"cell_type":"markdown","source":["## 4.1 Variational Autoencoder"],"metadata":{"id":"7-o8pdqRXV0v"}},{"cell_type":"code","source":["# We'll train it on MNIST digits\n","# Our VAE will be a subclass of Model, built as a nested composition of layers that\n","# subclass Layer.\n","# It willl feature a regularization loss (KL divergence)"],"metadata":{"id":"ofe5ImfvXYvw","executionInfo":{"status":"ok","timestamp":1641556068248,"user_tz":-540,"elapsed":290,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["# layers\n","from tensorflow.keras import layers\n","\n","class Sampling(layers.Layer):\n","    # Uses (z_mean, z_log_var) to sample z, the vector encoding a digit\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch,dim))\n","        return z_mean + tf.exp(0.5*z_log_var) * epsilon\n","\n","class Encoder(layers.Layer):\n","    # Maps MNIST digits to a triplet (z_mean, z_log_var, z).\n","\n","    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kargs):\n","        super(Encoder, self).__init__()\n","        self.dense_proj = layers.Dense(intermediate_dim, activation= 'relu')\n","        self.dense_mean = layers.Dense(latent_dim)\n","        self.dense_log_var = layers.Dense(latent_dim)\n","        self.sampling = Sampling()\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        z_mean = self.dense_mean(x)\n","        z_log_var = self.dense_log_var(x)\n","        z = self.sampling((z_mean, z_log_var))\n","        return z_mean, z_log_var, z\n","\n","class Decoder(layers.Layer):\n","    # Converts z, the encoded digit vector, back into a readable digit.\n","\n","    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kargs):\n","        super(Decoder, self).__init__(name=name, **kargs)\n","        self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n","        self.dense_output = layers.Dense(original_dim, activation= 'sigmoid')\n","\n","    def call(self, inputs):\n","        x = self.dense_proj(inputs)\n","        return self.dense_output(x)\n","\n","class KL_divergence(layers.Layer):\n","\n","    def __init__(self, exp= 0.5):\n","        super(KL_divergence, self).__init__()\n","        self.exp = exp\n","\n","    def call(self, z_mean, z_log_var, z):\n","        \n","        kl_loss = -self.exp * tf.reduce_mean(\n","            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n","        )\n","        self.add_loss(kl_loss)"],"metadata":{"id":"kiEi4qPlXcT6","executionInfo":{"status":"ok","timestamp":1641556155616,"user_tz":-540,"elapsed":261,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["# VAE model\n","class VariationalAutoEncoder(keras.Model):\n","    # Combines the encoder and decoder into an end-to-end model for training\n","    def __init__(self, \n","                 original_dim,\n","                 intermediate_dim=64,\n","                 latent_dim=32,\n","                 name=\"autoencoder\",\n","                 exp = 0.5,\n","                 **kargs\n","                ):\n","        super(VariationalAutoEncoder, self).__init__()\n","        self.original_dim = original_dim\n","        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n","        self.decoder = Decoder(original_dim=original_dim, intermediate_dim=intermediate_dim)\n","        self.kl = KL_divergence(exp)\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        reconstructed = self.decoder(z)\n","        # Add KL divergence regularization loss.\n","        self.kl(z_mean, z_log_var, z)\n","        # kl_loss = -0.5 * tf.reduce_mean(\n","        #     z_log_var - tf.square(z_mean) - tf.exp(z_log_var) +1\n","        # )\n","        # self.add_loss(kl_loss)\n","        return reconstructed\n"],"metadata":{"id":"ml9isA4ZXelS","executionInfo":{"status":"ok","timestamp":1641556155903,"user_tz":-540,"elapsed":2,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["# training loop for mnist\n","original_dim = 784\n","vae = VariationalAutoEncoder(original_dim, 64, 32)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate= 1e-3)\n","mse_loss_fn = tf.keras.losses.MeanSquaredError()\n","\n","loss_metric = tf.keras.metrics.Mean()\n","\n","(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n","x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n","train_dataset = train_dataset.shuffle(buffer_size= 1024).batch(64)\n","\n","epochs = 2\n","\n","# Iterate over epoches\n","for epoch in range(epochs):\n","\n","    print(f\"Start of epoch {epoch}\")\n","\n","    # Iterate over the batches of the dataset\n","    for step, x_batch_train in enumerate(train_dataset):\n","        with tf.GradientTape() as tape:\n","            reconstructed = vae(x_batch_train)\n","            loss = mse_loss_fn(x_batch_train, reconstructed)\n","            assert len(vae.losses) > 0\n","            loss += sum(vae.losses)\n","        grads = tape.gradient(loss, vae.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n","\n","        loss_metric(loss)\n","\n","        if step % 100 == 0:\n","            print(f\"step {step}: mean loss = {loss_metric.result():4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikGwp63JXxrP","executionInfo":{"status":"ok","timestamp":1641557139398,"user_tz":-540,"elapsed":42066,"user":{"displayName":"허성우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11849707056234337549"}},"outputId":"906371b8-0878-4073-a6e4-e3d1e128a02f"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["Start of epoch 0\n","step 0: mean loss = 0.361525\n","step 100: mean loss = 0.126191\n","step 200: mean loss = 0.099398\n","step 300: mean loss = 0.089305\n","step 400: mean loss = 0.084341\n","step 500: mean loss = 0.080981\n","step 600: mean loss = 0.078833\n","step 700: mean loss = 0.077227\n","step 800: mean loss = 0.076041\n","step 900: mean loss = 0.075009\n","Start of epoch 1\n","step 0: mean loss = 0.074718\n","step 100: mean loss = 0.074056\n","step 200: mean loss = 0.073552\n","step 300: mean loss = 0.073059\n","step 400: mean loss = 0.072737\n","step 500: mean loss = 0.072342\n","step 600: mean loss = 0.072026\n","step 700: mean loss = 0.071741\n","step 800: mean loss = 0.071506\n","step 900: mean loss = 0.071244\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"KZStlnklbHGU"},"execution_count":null,"outputs":[]}]}